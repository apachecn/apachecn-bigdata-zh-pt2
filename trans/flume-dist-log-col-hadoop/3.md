# 第三章：渠道

在水槽中，渠道是源和汇之间使用的结构。 它在从源读取动态事件之后为它们提供一个等待区域，直到可以将它们写入数据处理管道中的接收器。

我们将在这里介绍的两种类型是内存支持/非持久通道和本地文件系统支持/持久通道。 持久文件通道在向发送方确认收到事件之前刷新对磁盘的所有更改。 这比使用非持久内存通道慢得多，但在系统或 Flume 代理重新启动时提供可恢复性。 相反，内存通道要快得多，但故障会导致数据丢失，并且与支持文件通道的多 TB 磁盘相比，其存储容量要低得多。 您选择哪个渠道取决于您的特定使用案例、故障场景和风险承受能力。

也就是说，无论您选择哪个通道，如果您从源接收到通道的速率大于接收器可以写入数据的速率，您将超出通道的容量，并抛出`ChannelException`。 您的源对那个`ChannelException`做什么或不做什么是源特定的，但在某些情况下可能会丢失数据，因此您需要通过适当调整大小来避免填充通道。 事实上，您总是希望接收器能够比源输入更快地写入数据。 否则，你可能会陷入一旦你的水槽落后了，你就永远赶不上的境地。 如果您的数据量与站点使用情况保持一致，您可能会在白天拥有较高的数据量，而在晚上拥有较低的数据量，从而使您的通道有时间耗尽。 在实践中，您会希望尝试将通道深度(通道中当前的事件数)保持在尽可能低的水平，因为在通道中花费的时间会转化为到达最终目的地之前的时间延迟。

# 存储通道

正如预期的那样，存储器通道是在存储器中存储动态事件的通道。 由于内存(通常)比磁盘快几个数量级，因此可以更快地接收事件，从而减少硬件需求。 使用此通道的缺点是，代理故障(硬件问题、断电、JVM 崩溃、Flume 重启等)会导致数据丢失。 根据您的用例，这可能完全没有问题。 系统指标通常属于这一类，因为一些丢失的数据点并不是世界末日。 然而，如果你的活动是在你的网站上购物，那么记忆频道将是一个糟糕的选择。

要使用内存通道，请将命名通道上的`type`参数设置为`memory`。

```scala
agent.channels.c1.type=memory
```

这为名为`agent`的代理定义了名为`c1`的内存通道。

以下是可以根据默认值调整的配置参数的表格：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

钥匙 / 键 / 关键 / 主调

 | 

规定的

 | 

类型 / 品种 / 象征 / 印刷文字

 | 

不履行 / 拖欠 / 未到庭 / 不到场

 |
| --- | --- | --- | --- |
| `type` | 肯定的回答 / 赞成 / 是 | `String` | 记忆力 / 记忆中事物 / 回忆 / 存储器 |
| `capacity` | 不 / 否决票 / 同 Noh | `int` | 100 个 |
| `transactionCapacity` | 不 / 否决票 / 同 Noh | `int` | 100 个 |
| `byteCapacityBufferPercentage` | 不 / 否决票 / 同 Noh | Колибри(%)Колибри | 20% |
| `byteCapacity` | 不 / 否决票 / 同 Noh | `long`(字节) | 80%的 JVM 堆 |
| `keep-alive` | 不 / 否决票 / 同 Noh | `int` | 3(秒) |

此通道的默认容量为100个事件。 这可以通过设置`capacity`属性来调整，如下所示：

```scala
agent.channels.c1.capacity=200
```

记住如果您增加了这个值，您可能还必须使用`-Xmx`和可选的`-Xms`参数来增加Java堆空间。

您可以设置的另一个与容量相关的设置是`transactionCapacity`。 这是源的`ChannelProcessor`(负责在单个事务中将数据从源移动到通道的组件)可以写入的最大事件数，也称为 PUT。 这也是负责将数据从通道移动到接收器的组件`SinkProcessor`在单个事务中可以读取的事件数，也称为 Take。 您可能希望将此值设置得更高，以减少事务包装器的开销，这可能会加快速度。 如果出现故障，增加这个值的不利之处在于，源将不得不回滚更多数据。

### 提示

Flume 仅为每个单独代理中的每个通道提供事务保证。 在多代理中，多通道配置重复和无序交付是可能的，但不应被视为标准。 如果您在无故障条件下获得重复项，则意味着您需要继续调整您的 Flume 配置。

如果您使用的接收器写入的位置受益于较大批处理的工作(例如 HDFS)，则可能需要将其设置得更高。 与许多事情一样，确保的唯一方法是使用不同的值运行性能测试。 Flume 提交者 Mike Percy 的博客文章[http://bit.ly/flumePerfPt1](http://bit.ly/flumePerfPt1)应该会给您一些很好的起点。

[https://issues.apache.org/jira/browse/FLUME-1535](https://issues.apache.org/jira/browse/FLUME-1535)中引入了`byteCapacityBufferPercentage`和`byteCapacity`参数，作为一种使用字节而不是事件数量来调整内存通道容量的方法，并试图避免`OutOfMemoryErrors`。 如果事件的大小差异很大，您可能会尝试使用这些设置来调整容量，但请注意，计算仅从事件的正文进行估计。 如果您有任何标头(您会这样做)，则您的实际内存使用量将高于配置的值。

最后，`keep-alive`参数是将数据写入通道的线程在通道满后放弃之前等待的时间。 由于同时从通道中排出数据，因此如果在超时到期之前释放空间，则数据将写入通道，而不是向源抛出异常。 您可能会想要将此值设置得非常高，但请记住，等待对通道的写入会阻止流入源的数据，这可能会导致上游代理中的数据备份。 最终，这可能会导致事件被丢弃。 您需要针对流量的周期性高峰以及临时计划内(和计划外)维护进行规模调整。

# 帖子主题：Re：Колибри

文件通道是将事件存储到代理的本地文件系统的通道。 虽然它比内存通道慢，但它提供了一个持久的存储路径，可以经受住大多数问题，并且应该在数据流中的间隙不受欢迎的情况下使用。

这种耐用性由**预写日志**(**WAL**)和一个或多个文件存储目录的组合提供。 WAL 用于以原子安全的方式跟踪通道的所有输入和输出。 这样，如果代理重新启动，则可以重放 WAL，以确保在可以从本地文件系统清除数据存储之前，所有进入通道(PUT)的事件都已被写出(Take)。

此外，如果您的数据处理策略要求加密磁盘上的所有数据(即使是临时的)，则文件通道支持加密写入文件系统的数据。 我不会在这里介绍这一点，但是如果您需要的话，在 Flume 用户指南([http://flume.apache.org/FlumeUserGuide.html](http://flume.apache.org/FlumeUserGuide.html))中有一个示例。 请记住，使用加密会降低文件通道的吞吐量。

要使用文件通道，请将命名通道上的`type`参数设置为`file`：

```scala
agent.channels.c1.type=file
```

这为名为`agent`的代理定义了名为`c1`的文件通道。

以下是可以根据默认值调整的配置参数的表格：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

钥匙 / 键 / 关键 / 主调

 | 

规定的

 | 

类型 / 品种 / 象征 / 印刷文字

 | 

不履行 / 拖欠 / 未到庭 / 不到场

 |
| --- | --- | --- | --- |
| `type` | 肯定的回答 / 赞成 / 是 | `String` | 文件夹 / 卷宗 / 文件 / 锉刀 |
| `checkpointDir` | 没有Колибрисистема | `String` | `~/.flume/file-channel/checkpoint` |
| `dataDirs` | 没有Колибрисистема | `String`(逗号分隔列表) | `~/.flume/file-channel/data` |
| `capacity` | 没有Колибрисистема | `int` | 1000000 |
| `keep-alive` | 没有Колибрисистема | `int` | 3(秒) |
| `transactionCapacity` | 没有Колибрисистема | `int` | 1000 |
| `checkpointInterval` | 没有Колибрисистема | `long` | 300000(毫秒-5 分钟) |
| `write-timeout` | 没有Колибрисистема | `int` | 10(秒) |
| `maxFileSize` | 没有Колибрисистема | `long` | 2146435071(字节) |
| `minimumRequiredSpace` | 没有Колибрисистема | `long` | 524288000(字节) |

要指定 Flume 代理应保存数据的位置，请设置`checkpointDir`和`dataDirs`属性：

```scala
agent.channels.c1.checkpointDir=/flume/c1/checkpoint
agent.channels.c1.dataDirs=/flume/c1/data
```

从技术上讲，这些属性不是必需的，并且具有合理的开发默认值。 但是，如果您的代理中配置了多个文件通道，则只会启动第一个通道。 对于具有多个文件通道的生产部署和开发工作，您应该为每个文件通道存储区域使用不同的目录路径，并考虑将不同的通道放置在不同的磁盘上，以避免 IO 争用。 此外，如果您要调整大型计算机的大小，请考虑使用某种形式的包含条带化的 RAID(RAID 10、50、60)来实现更高的磁盘性能，而不是购买更昂贵的 10k 或 15k 驱动器或固态硬盘。 如果您没有 RAID 条带化，但有多个磁盘，请将`dataDirs`设置为每个存储位置的逗号分隔列表。 使用多个磁盘将几乎与条带式 RAID 一样分散磁盘流量，但不会产生与 RAID 50/60 相关的计算开销以及与 RAID 10 相关的 50%空间浪费。您需要测试您的系统，以了解 RAID 开销是否值得进行速度差异。 由于硬盘故障是事实，您可能更喜欢某些 RAID 配置，而不是单个磁盘，以避免与单个驱动器故障相关的数据丢失。

出于同样的原因，应该避免使用 NFS 存储。 使用 JDBC 通道不是一个好主意，因为它会引入瓶颈和单点故障，而不是应该设计成高度分布式的系统。

### 提示

请确保在使用文件通道时设置了`HADOOP_PREFIX`和`JAVA_HOME`环境变量。 虽然我们似乎没有使用任何特定于 Hadoop 的东西(比如写入 HDFS)，但文件通道使用 Hadoop`Writeables`作为磁盘上的序列化格式。 如果 Flume 找不到 Hadoop 库，您可能会在启动时看到这一点，因此请检查您的环境变量：

`java.lang.NoClassDefFoundError: org/apache/hadoop/io/Writable`

无论事件内容的大小如何，默认文件通道`capacity`都是一百万个事件。 如果达到信道容量，源将无法再接收数据。 此缺省值应该适用于低容量情况。 如果您的摄取足够重，以至于无法忍受正常的计划内或计划外停机，那么您会想要更大一些。 例如，您可以在 Hadoop 中进行许多需要重新启动集群的配置更改。 如果您让 Flume 将重要数据写入 Hadoop，那么文件通道的大小应该调整为能够容忍重新启动 Hadoop 所需的时间(或许还可以为意外情况添加一个舒适的缓冲区)。 如果您的群集或其他系统不可靠，您可以将其设置得更高，以处理更长的停机时间。 在某些情况下，您会遇到这样一个事实，即您的磁盘空间是有限的资源，因此您将不得不选择一些上限(或者购买更大的磁盘)。

`keep-alive`参数类似于内存通道的参数。它是源在放弃之前尝试写入满通道时等待的最长时间。 如果空间在超时前变得可用，则写入成功；否则将向源抛出`ChannelException`。

属性`transactionCapacity`是单个事务中允许的最大事件数。 对于将事件批处理在一起并在单个调用中将它们传递给通道的某些源，这可能会变得很重要。 最有可能的情况是，您不需要更改默认设置。 将该值设置得更高会在内部分配额外的资源，因此除非遇到性能问题，否则不应增加该值。

`checkpointInterval`属性是执行检查点之间的毫秒数(这还会滚动写入`logDirs`的日志文件)。 您不能将其设置为低于 1000 毫秒。

检查点文件也使用`maxFileSize`属性根据写入它们的数据量进行滚动。 如果您想尝试节省一些磁盘空间，可以降低低通信量通道的此值。 假设您的最大文件大小为 50,000 字节，但您的通道每天仅写入 500 字节，则需要 100 天才能填满单个日志。 假设您是在第 100 天，所有 2000 个字节都是一次性传入的。 一些数据将被写入旧文件，而新文件将开始溢出。 滚动之后，Flume 尝试删除任何不再需要的日志文件。 由于完整日志中有未处理的记录，因此目前还不能将其删除。 下一次清理旧日志文件的机会可能还要再过 100 天才会到来。 旧的 50,000 字节文件保留更长时间可能并不重要，但是由于默认大小约为 2 GB，因此每个通道使用的磁盘空间可能是该大小的两倍(4 GB)。 这取决于您有多少可用磁盘，以及您的代理中配置的通道数，这可能是问题，也可能不是问题。 如果您的机器有足够的存储空间，默认设置应该可以。

最后，`minimumRequiredSpace`属性是您不希望用于写入日志的空间量。 如果您尝试使用与`dataDir`路径关联的磁盘的最后 500MB，则默认配置将引发异常。 此限制适用于所有通道，因此如果您配置了三个文件通道，则上限仍为 500 MB，而不是 1.5 GB。 您可以将此值设置为低至 1MB，但一般来说，当您将磁盘利用率推向 100%时，往往会发生不好的事情。

# 摘要

在本章中，我们介绍了您最有可能在数据处理管道中使用的两种通道类型。

存储器通道在发生故障时以数据丢失为代价提供速度。

或者，文件通道提供更可靠的传输，因为它可以容忍代理故障和重启，但以性能为代价。

您需要决定哪个渠道适合您的用例。 在尝试确定内存通道是否合适时，问问自己，如果丢失一些数据，需要付出多少金钱代价。 在决定是否需要持久通道时，要权衡一下增加硬件以弥补性能差异的额外成本。 另一个考虑因素是数据是否可以重新发送。 并不是您可能接收到 Hadoop 的所有数据都来自流式应用程序日志。 如果您每天都收到数据下载，您可以使用内存通道逃脱惩罚，因为如果您遇到问题，您可以随时重新运行导入。

### 提示

可能的(或故意的)重复事件是摄取流数据的事实。 有些人会定期运行 MapReduce 作业来清理数据(并在使用数据时删除重复项)。 其他人在运行 MapReduce 作业时将只考虑重复项，这节省了额外的后处理。 在实践中，您可能会两者兼而有之。

在下一章中，我们将研究接收器，特别是用于将事件写入 HDFS 的 HDFS 接收器。 我们还将介绍事件序列化程序，它指定如何将 Flume 事件转换为更适合接收器的输出。 最后，我们将介绍汇聚处理器，以及如何在分层配置中设置负载平衡和故障路径，以实现更健壮的数据传输。