# 第 6 章：拦截程序、ETL 和路由

数据处理管道中需要的最后一项功能是检查和转换飞行中的事件的能力。 这可以使用拦截器来完成。 **拦截器**，正如我们在[第 1 章](1.html "Chapter 1. Overview and Architecture")，*概述和体系结构*中所讨论的，可以插入源之后或汇之前。

# 拦截器

拦截器的功能可以用以下方法总结：

```scala
public Event intercept(Event event);
```

它作为 Flume**事件**传递，并作为Flume**事件**返回。 它可能什么也不做；也就是说，返回相同的未更改的事件。 通常，它会以某种有用的方式改变事件。 如果返回`null`，则丢弃该事件。

要将拦截器添加到源，只需将`interceptors`属性添加到指定的源。 例如：

```scala
agent.sources.s1.interceptors=i1 i2 i3
```

这在名为`agent`的代理的`s1`源上定义了三个拦截器`i1`、`i2`和`i3`。

### 备注

拦截器按照列出的顺序运行。 在前面的示例中，`i2`将接收来自`i1`的输出。 `i3`将接收来自`i2`的输出。 最后，通道选择器接收来自`i3`的输出。

既然我们已经按名称定义了拦截器，我们需要按如下方式指定其类型：

```scala
agent.sources.s1.interceptors.i1.type=TYPE1
agent.sources.s1.interceptors.i1.additionalProperty1=VALUE
agent.sources.s1.interceptors.i2.type=TYPE2
agent.sources.s1.interceptors.i3.type=TYPE3
```

让我们看看 Flume 附带的一些拦截器，以便更好地了解如何配置它们。

## 加入时间：清华大学 2007 年 01 月 25 日下午 3：33

时间戳拦截器，正如它的名字所暗示的那样，在 Flume 事件中添加一个带有`timestamp`键的头(如果不存在的话)。 要使用它，请将`type`属性设置为`timestamp`。

如果事件已包含时间戳头，则它将被当前时间覆盖，除非通过将`preserveExisting`属性设置为`true`将其配置为保留原始值。

下表汇总了时间戳拦截器的属性：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

钥匙 / 键 / 关键 / 主调

 | 

规定的

 | 

类型 / 品种 / 象征 / 印刷文字

 | 

不履行 / 拖欠 / 未到庭 / 不到场

 |
| --- | --- | --- | --- |
| `type` | 肯定的回答 / 赞成 / 是 | `String` | `timestamp` |
| `preserveExisting` | 没有Колибрисистема | `Boolean` | `false` |

如果我们只希望源在不存在时间戳头的情况下添加时间戳头，则源的总配置可能如下所示：

```scala
agent.sources.s1.interceptors=i1
agent.sources.s1.interceptors.i1.type=timestamp
agent.sources.s1.interceptors.i1.preserveExisting=true
```

调用[第 4 章](4.html "Chapter 4. Sinks and Sink Processors")，*接收器和接收器处理器*中的 HDFSSink 路径，使用事件日期：

```scala
agent.sinks.k1.hdfs.path=/logs/apache/%Y/%m/%D/%H
```

`timestamp`标头决定了这条路径。 如果缺少该文件，可以肯定 Flume 不知道在哪里创建文件，也不会得到您想要的结果。

## 主机

在简单性上类似于时间戳拦截器，主机拦截器将向包含当前 Flume 代理的 IP 地址的事件添加标头。 要使用它，请将`type`属性设置为`host`。

```scala
agent.sources.s1.interceptors=i1
agent.sources.s1.interceptors.type=host
```

除非您使用`hostHeader`属性指定其他内容，否则此标头的键将为`host`。 与前面一样，除非将`preserveExisting`属性设置为`true`，否则现有标头将被覆盖。 最后，如果希望使用主机名的反向 DNS 查找代替 IP 作为值，请将`useIP`属性设置为`false`。 请记住，反向查找会增加数据流的处理时间。

下表汇总了主机拦截器的属性：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

钥匙 / 键 / 关键 / 主调

 | 

规定的

 | 

类型 / 品种 / 象征 / 印刷文字

 | 

不履行 / 拖欠 / 未到庭 / 不到场

 |
| --- | --- | --- | --- |
| `type` | 是 | `String` | `host` |
| `hostHeader` | 没有Колибрисистема | `String` | `host` |
| `preserveExisting` | 没有Колибрисистема | `Boolean` | `false` |
| `useIP` | 没有Колибрисистема | `Boolean` | `true` |

如果我们只希望源将包含此代理的 DNS 主机名的`relayHost`标头添加到每个事件，则源的总配置可能如下所示：

```scala
agent.sources.s1.interceptors=i1
agent.sources.s1.interceptors.i1.type=host
agent.sources.s1.interceptors.i1.hostHeader=relayHost
agent.sources.s1.interceptors.i1.useIP=false
```

例如，如果您想要记录事件通过数据流的路径，此拦截器可能会很有用。 您可能更感兴趣的是事件的起源，而不是它所经历的路径，这就是为什么我还没有用到这一点的原因。

## 静态

静态拦截器用于在处理的每个 Flume 事件中插入任何单个键/值头。 如果需要多个键/值，只需添加额外的静态拦截器。 与我们到目前为止看到的拦截器不同，默认行为是使用相同的键保留个现有标头。 一如既往，我的建议是始终指定您想要的内容，而不是依赖缺省值。

我不知道为什么键和值属性不是必需的，因为缺省值并不是特别有用。

下表总结了静态侦听器的属性：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

钥匙 / 键 / 关键 / 主调

 | 

规定的

 | 

类型 / 品种 / 象征 / 印刷文字

 | 

不履行 / 拖欠 / 未到庭 / 不到场

 |
| --- | --- | --- | --- |
| `type` | 是 | `String` | `static` |
| `key` | 没有Колибрисистема | `String` | `key` |
| `value` | 没有Колибрисистема | `String` | `value` |
| `preserveExisting` | 没有Колибрисистема | `Boolean` | `true` |

最后，让我们看一个示例配置，该配置插入两个新的标头，前提是事件中不存在这两个标头：

```scala
agent.sources.s1.interceptors=pos env
agent.sources.s1.interceptors.pos.type=static
agent.sources.s1.interceptors.pos.key=pointOfSale
agent.sources.s1.interceptors.pos.value=US
agent.sources.s1.interceptors.env.type=static
agent.sources.s1.interceptors.env.key=environment
agent.sources.s1.interceptors.env.value=staging
```

## 正则表达式过滤

如果您希望根据正文内容过滤事件，则正则表达式过滤拦截器是您的选择。 根据您提供的正则表达式，它将过滤出匹配的事件或仅保留匹配的事件。 首先将拦截器的`type`属性设置为`regex_filter`。 您想要匹配的模式是使用 Java 样式的正则表达式语法指定的。 有关用法详细信息，请参阅以下 javadoc：

[http：//docs.oracle.com/javase/6/docs/api/java/util/regex/Pattern.html](http://docs.oracle.com/javase/6/docs/api/java/util/regex/Pattern.html)。

模式字符串在`regex`属性中设置。 最后，您需要通过将`excludeEvents`属性设置为`true`来告诉拦截器是否要排除匹配的记录。 默认值(`false`)表示您只希望保持事件与模式匹配。

下表汇总了正则表达式过滤拦截器的属性：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

钥匙 / 键 / 关键 / 主调

 | 

规定的

 | 

类型 / 品种 / 象征 / 印刷文字

 | 

不履行 / 拖欠 / 未到庭 / 不到场

 |
| --- | --- | --- | --- |
| `type` | 是 | `String` | `regex_filter` |
| `regex` | 没有Колибрисистема | `String` | `.*` |
| `excludeEvents` | 没有Колибрисистема | `Boolean` | `false` |

在此示例中，将删除包含字符串`NullPointerException`的任何事件：

```scala
agent.sources.s1.interceptors=npe
agent.sources.s1.interceptors.npe.type=regex_filter
agent.sources.s1.interceptors.npe.regex=NullPointerException
agent.sources.s1.interceptors.npe.excludeEvents=true
```

## 正则表达式提取器

有时，您可能会希望将事件主体的部分提取到 Flume 标头中，这样您就可以通过通道选择器执行路由。 您可以使用正则表达式提取器拦截器来执行此功能。 首先将拦截器`type`设置为`regex_extractor`。

```scala
agent.sources.s1.interceptors=e1
agent.sources.s1.interceptors.e1.type=regex_extractor
```

与正则表达式过滤拦截器类似，正则表达式提取器使用 Java 样式的正则表达式语法。 要提取一个或多个字段，首先需要使用组匹配圆括号指定`regex`属性。 假设我们要在事件中查找“Error：N”形式的错误号，其中*N*是某个数字：

```scala
agent.sources.s1.interceptors=e1
agent.sources.s1.interceptors.e1.type=regex_extractor
agent.sources.s1.interceptors.e1.regex=Error:\\s(\\d+)
```

如您所见，我用捕获括号将数字括起来，数字可能由一个或多个数字组成。 现在我已经匹配了我想要的模式，我需要告诉 Flume 如何处理我的匹配。 这里我们需要介绍**序列化程序**，它为如何解释每个匹配提供了一种可插拔的机制。 在本例中，我只有一个匹配项，因此我的以空格分隔的序列化程序名称列表只有一个条目：

```scala
agent.sources.s1.interceptors=e1
agent.sources.s1.interceptors.e1.type=regex_extractor
agent.sources.s1.interceptors.e1.regex=Error:\\s(\\d+)
agent.sources.s1.interceptors.e1.serializers=ser1
agent.sources.s1.interceptors.e1.serializers.ser1.type=default
agent.sources.s1.interceptors.e1.serializers.ser1.name=error_no
```

`name`属性指定要在值是来自正则表达式的匹配文本的情况下使用的事件键。 `default`的类型(如果未指定也是默认类型)是一个简单的直通串行化程序。 对于以下事件正文：

```scala
NullPointerException: A problem occurred. Error: 123\. TxnID: 5X2T9E.
```

以下标头将添加到事件中：

```scala
{ "error_no":"123" }
```

如果我想添加`TxnID`值作为标题，我只需添加另一个匹配的模式组和序列化程序：

```scala
agent.sources.s1.interceptors=e1
agent.sources.s1.interceptors.e1.type=regex_extractor
agent.sources.s1.interceptors.e1.regex=Error:\\s(\\d+).*TxnID:\\s(\\w+)
agent.sources.s1.interceptors.e1.serializers=ser1 ser2
agent.sources.s1.interceptors.e1.serializers.ser1.type=default
agent.sources.s1.interceptors.e1.serializers.ser1.name=error_no
agent.sources.s1.interceptors.e1.serializers.ser2.type=default
agent.sources.s1.interceptors.e1.serializers.ser2.name=txnid
```

这将为上述输入创建以下标头：

```scala
{ "error_no":"123", "txnid":"5x2T9E" }
```

但是，如果字段反转，如下所示：

```scala
NullPointerException: A problem occurred. TxnID: 5X2T9E. Error: 123.
```

我最终只得到了`TxnID`的头。 处理这种排序的更好方法是使用多个拦截器，这样顺序就不重要了：

```scala
agent.sources.s1.interceptors=e1 e2
agent.sources.s1.interceptors.e1.type=regex_extractor
agent.sources.s1.interceptors.e1.regex=Error:\\s(\\d+)
agent.sources.s1.interceptors.e1.serializers=ser1
agent.sources.s1.interceptors.e1.serializers.ser1.type=default
agent.sources.s1.interceptors.e1.serializers.ser1.name=error_no
agent.sources.s1.interceptors.e2.type=regex_extractor
agent.sources.s1.interceptors.e2.regex=TxnID:\\s(\\w+)
agent.sources.s1.interceptors.e2.serializers=ser1
agent.sources.s1.interceptors.e2.serializers.ser1.type=default
agent.sources.s1.interceptors.e2.serializers.ser1.name=txnid
```

除直通之外，Flume 附带的唯一其他类型的序列化程序实现是指定完全限定的类名`org.apache.flume.interceptor.RegexExtractorInterceptorMillisSerializer`。 此序列化程序用于将时间转换回毫秒。 您需要基于`org.joda.time.format.DateTimeFormat`模式指定模式属性。

例如，假设您正在接收 Apache Web 服务器访问日志。 例如：

```scala
192.168.1.42 - - [29/Mar/2013:15:27:09 -0600] "GET /index.html HTTP/1.1" 200 1037
```

此表达式的完整正则表达式可能如下所示(以 Java 字符串的形式，使用额外的反斜杠转义反斜杠和引号)：

```scala
^([\\d.]+) \\S+ \\S+ \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(.+?)\" (\\d{3}) (\\d+)
```

匹配的时间模式对应于`org.joda.time.format.DateTimeFormat`模式：

```scala
yyyy/MMM/dd:HH:mm:ss Z
```

这使得我们的配置类似于以下代码：

```scala
agent.sources.s1.interceptors=e1
agent.sources.s1.interceptors.e1.type=regex_extractor
agent.sources.s1.interceptors.e1.regex=^([\\d.]+) \\S+ \\S+ \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(.+?)\" (\\d{3}) (\\d+)
agent.sources.s1.interceptors.e1.serializers=ip dt url sc bc
agent.sources.s1.interceptors.e1.serializers.ip.name=ip_address
agent.sources.s1.interceptors.e1.serializers.dt.type=org.apache.flume.interceptor.RegexExtractorInterceptorMillisSerializer
agent.sources.s1.interceptors.e1.serializers.dt.pattern=yyyy/MMM/dd:HH:mm:ss Z
agent.sources.s1.interceptors.e1.serializers.dt.name=timestamp
agent.sources.s1.interceptors.e1.serializers.url.name=http_request
agent.sources.s1.interceptors.e1.serializers.sc.name=status_code
agent.sources.s1.interceptors.e1.serializers.bc.name=bytes_xfered
```

这将为前述样本创建以下个标头：

```scala
{ "ip_address":"192.168.1.42", "timestamp":"1364588829", "http_request":"GET /index.html HTTP/1.1", "status_code":"200", "bytes_xfered":"1037" }
```

正文内容不受影响。 您还会注意到，我没有为其他序列化程序的类型指定`default`，因为这是默认设置。

### 备注

此侦听器类型中没有覆盖检查。 例如，使用`timestamp`键将覆盖事件的上一个时间值(如果有)。

您可以通过实现`org.apache.flume.interceptor.RegexExtractorInterceptorSerializer`接口为该拦截器实现您自己的序列化程序。 但是，如果您的目标是将数据从事件正文移动到标题，则可能需要实现一个自定义拦截器，以便除了设置标题值之外还可以更改正文内容，否则数据将被有效地复制。

总之，让我们回顾一下此拦截器的属性：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

钥匙 / 键 / 关键 / 主调

 | 

规定的

 | 

类型 / 品种 / 象征 / 印刷文字

 | 

不履行 / 拖欠 / 未到庭 / 不到场

 |
| --- | --- | --- | --- |
| `type` | 是 | `String` | Regex_ 提取器 |
| `regex` | 是 | `String` |   |
| `serializers` | 是 | 以空格分隔的序列化程序名称列表 |   |
| `serializers.NAME.name` | 是 | `String` |   |
| `serializers.NAME.type` | 没有Колибрисистема | 实施的默认或 FQDN | `default` |
| `serializers.NAME.PROP` | 没有Колибрисистема | 序列化程序特定的属性 |   |

## 自定义拦截器

如果有一段自定义代码要添加到您的 Flume 实现中，那么它很可能是一个自定义拦截器。 如前所述，您实现了`org.apache.flume.interceptor.Interceptor`接口和相关的`org.apache.flume.interceptor.Interceptor.Builder`接口。

假设我需要对我的事件主体进行 URL 解码。 代码如下所示：

```scala
public class URLDecode implements Interceptor {

  public void initialize() {}

  public Event intercept(Event event) {
    try {
      byte[] decoded = URLDecoder.decode(new String(event.getBody()), "UTF-8").getBytes("UTF-8");
      event.setBody(decoded);
    } catch UnsupportedEncodingException e) {
      // This shouldn't happen. Fall through to unaltered event.
    }
    return event;
  }

  public List<Event> intercept(List<Event> events) {
    for (Event event:events) {
      intercept(event);
    }
    return events;
  }

  public void close() {}

  public static class Builder implements Interceptor.Builder {
    public Interceptor build() {
      return new URLDecode();
    }
    public void configure(Context context) {}
  }
}
```

然后，要配置我的新拦截器，请使用`Builder`类的 FQDN 作为类型：

```scala
agent.sources.s1.interceptors=i1
agent.sources.s1.interceptors.i1.type=com.example.URLDecoder$Builder
```

有关如何传递和验证属性的更多示例，请查看现有拦截器实现中的 Flume 源代码以获取灵感。

请记住，自定义拦截器中的任何繁重处理都会影响总体吞吐量，因此请注意实现中的对象混乱或计算密集型处理。

# 对数据流进行分层

在[第 1 章](1.html "Chapter 1. Overview and Architecture")，*概述和体系结构*中，我们讨论了对数据流进行分层。 想要这样做有几个原因。 您可能希望限制直接连接到 Hadoop集群的 Flume 代理的数量，以限制并行请求的数量。 在对 Hadoop 集群执行维护时，您的应用程序服务器上也可能缺少足够的磁盘空间来存储大量数据。 无论您的原因或用例如何，链接 Flume 代理的最常见机制是使用 Avro Source/Sink 对。

## КолибрифайлаAVRO 信源/信宿

当我们讨论将 Avro a位用作 HDFS 中存储的文件的磁盘序列化格式时，我们在[章](4.html "Chapter 4. Sinks and Sink Processors")，*Sink and Sink Processor*中介绍了 Avro a位。 在这里，我们将把它用于水槽特工之间的通信。 典型配置可能如下所示：

![Avro Source/Sink](graphics/7914_06_01.jpg)

要使用 Avro Source，您需要指定`type`属性的值`avro`。 您需要提供要侦听的绑定地址和端口号：

```scala
collector.sources=av1
collector.sources.av1.type=avro
collector.sources.av1.bind=0.0.0.0
collector.sources.av1.port=42424
collector.sources.av1.channels=ch1
collector.channels=ch1
collector.channels.ch1.type=memory
collector.sinks=k1
collector.sinks.k1.type=hdfs
collector.sinks.k1.channel=ch1
collector.sinks.k1.hdfs.path=/path/in/hdfs
```

在这里，我们已经配置了右侧的代理，它侦听端口 42424，使用内存通道，并写入 HDFS。 这里，我使用了内存通道来简化这个示例配置。 另外，请注意，为了避免混淆，我为该代理指定了一个不同的名称`collector`。

左侧的代理-馈送收集器层-可能具有类似如下的配置。 为简洁起见，我在此配置中去掉了源代码：

```scala
client.channels=ch1
client.channels.ch1.type=memory
client.sinks=k1
client.sinks.k1.type=avro
client.sinks.k1.channel=ch1
client.sinks.k1.hostname=collector.example.com
client.sinks.k1.port=42424
```

`hostname`值`collector.example.com`与该计算机上的代理名称无关，它是具有接收 Avro 源的目标计算机的主机名(或者您可以使用 IP)。 此名为`client`的配置将应用于左侧的两个代理，假设两者具有相似的源配置。

由于我不喜欢单点故障，因此我将使用前面的配置配置两个收集器代理，并使用接收器组将每个客户端代理设置为在这两个代理之间进行循环调度。 为了简短起见，我再一次省略了这些来源：

```scala
client.channels=ch1
client.channels.ch1.type=memory
client.sinks=k1 k2
client.sinks.k1.type=avro
client.sinks.k1.channel=ch1
client.sinks.k1.hostname=collectorA.example.com
client.sinks.k1.port=42424
client.sinks.k2.type=avro
client.sinks.k2.channel=ch1
client.sinks.k2.hostname=collectorB.example.com
client.sinks.k2.port=42424
client.sinkgroups=g1
client.sinkgroups.g1=k1 k2
client.sinkgroups.g1.processor.type=load_balance
client.sinkgroups.g1.processor.selector=round_robin
client.sinkgroups.g1.processor.backoff=true
```

## 发帖主题：Re：Колибри0.7.0

Avro 源也可以与您在[第 2 章](2.html "Chapter 2. Flume Quick Start")、*Flume 快速入门*中注意到的命令行选项之一结合使用。 您可以将`avro-client`参数传递给将一个或多个文件发送到 Avro 源，而不是使用`agent`参数运行`flume-ng`。 以下是帮助文本中的`avro-client`特定选项：

```scala
avro-client options:
  --dirname <dir>       directory to stream to avro source
  --host,-H <host>      hostname to which events will be sent (required)
  --port,-p <port>      port of the avro source (required)
  --filename,-F <file>  text file to stream to avro source [default: std input]
  --headerFile,-R <file> headerFile containing headers as key/value pairs on each new line
  --help,-h             display help text
```

此变体对于测试、因错误而手动重新发送数据或导入存储在其他地方的较旧数据非常有用。

就像 Avro Sink 一样，您必须指定要向其发送数据的主机名和端口。 您可以使用`--filename`选项发送单个文件，也可以使用`--dirname`选项发送目录中的所有文件。 如果两者都不指定，则将使用`stdin`。 下面介绍如何将名为`foo.log`的文件发送到我们之前配置的 Flume 代理中：

```scala
$ ./flume-ng avro-client --filename foo.log --host collector.example.com --port 42424
```

输入的每一行都将转换为单个 Flume 事件。

(可选)可以指定包含键/值对的文件来设置 Flume 标头值。 该文件使用 Java 属性文件语法。 如果我有一个名为`headers.properties`的文件：

```scala
pointOfSale=US
environment=staging
```

然后，包括`--headerFile`选项将在创建的每个事件上设置这两个标头：

```scala
$ ./flume-ng avro-client --filename foo.log --headerFile headers.properties --host collector.example.com --port 42424
```

## Log4J 附加器

正如我们在[第 5 章](5.html "Chapter 5. Sources and Channel Selectors")，*源和频道选择器*中讨论的，使用文件系统文件作为源可能会出现问题。 避免此问题的一种方法是在 Java 应用程序中使用 Flume Log4J 附加器。 在引擎盖下，它使用与 Avro Sink 相同的 Avro 通信，因此您只需将其配置为将数据发送到 Avro Source。

附加器有两个属性，如 XML 所示：

```scala
<appender name="FLUME" class="org.apache.flume.clients.log4jappender.Log4jAppender">
  <param name="Hostname" value="collector.example.com"/>
  <param name="Port" value="42424"/>
</appender>
```

正文的格式将由附加器的配置布局(未显示)决定。 下表汇总了映射到Flume 标题的`log4j`字段：

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

凹槽标题键

 | 

Log4J LoggingEvent 字段

 |
| --- | --- |
| `flume.client.log4j.logger.name` | `event.getLoggerName()` |
| `flume.client.log4j.log.level` | `event.getLevel()`作为一个数字。 有关映射，请参见`org.apache.log4j.Level`。 |
| `flume.client.log4j.timestamp` | `event.getTimeStamp()` |
| `flume.client.log4j.message.encoding` | 不适用。始终为`UTF8`。 |
| `flume.client.log4j.logger.other` | 只有当在映射前面的一个字段时出现问题时，才会看到-所以通常不会出现这种情况。 |

有关使用 http://logging.apache.org/log4j/1.2/的更多详细信息，请参见[Log4J](http://logging.apache.org/log4j/1.2/)。

您需要在运行时将`flume-ng-sdk`JAR 包含在 Java 应用程序的类路径中，才能使用 Flume 的 Log4J 附加器。

请记住，如果向 Avro Source 发送数据时出现问题，附加器将抛出异常，并且日志消息将被丢弃，因为没有地方放置它。 将其保存在内存中可能会使您的 JVM 堆很快超载，这通常被认为比删除数据记录更糟糕。

## 负载均衡 Log4J 附加器

我相信您已经注意到，以前的 Log4j 附加器在其配置中只有一个主机名/端口。 如果要跨多个收集器代理分布负载，无论是为了增加容量还是为了容错，可以使用`LoadBalancingLog4jAppender`。 此附加器有一个名为`Hosts`的必需属性，它是由冒号分隔的主机名和端口号的空格列表，如下所示：

```scala
<appender name="FLUME" class="org.apache.flume.clients.log4jappender.LoadBalancingLog4jAppender">
  <param name="Hosts" value="server1:42424 server2:42424"/>
</appender>
```

有一个可选属性`Selector`，它指定要进行负载平衡的方法。 有效值为`RANDOM`和`ROUND_ROBIN`。 如果未指定，则默认为`RANDOM`。 您可以实现自己的选择器，但这超出了本书的范围。 如果您感兴趣，请查看`LoadBalancingLog4jAppender`类的文档齐全的源代码。

### 备注

负载平衡 Log4J 附加器的默认选择器机制(如果未指定)是随机的。 您将注意到，这与[第 4 章](4.html "Chapter 4. Sinks and Sink Processors")，*接收器和接收器处理器*中介绍的接收器组的类似功能不同，后者的默认选择器值是循环调度。

这是为什么您应该始终指定您想要的，而不是依赖缺省值的另一个例子。

最后，还有另一个可选属性，用于在无法联系服务器时覆盖指数回退的最长时间。 最初，如果无法联系到服务器，则需要一秒钟后才能重试该服务器。 每次服务器不可用时，重试时间都会加倍，最长默认为 30 秒。 如果我们想要将此最大值增加到 2 分钟，我们可以指定一个`MaxBackoff`属性，单位为毫秒，如下所示：

```scala
<appender name="FLUME" class="org.apache.flume.clients.log4jappender.LoadBalancingLog4jAppender">
  <param name="Hosts" value="server1:42424 server2:42424"/>
  <param name="Selector" value="ROUND_ROBIN"/>
  <param name="MaxBackoff" value="120000"/>
</appender>
```

在本例中，我们还覆盖了默认的随机选择器，以使用循环选择。

# 工艺路线

既然您已经了解了 Flume 中的所有各种机制，那么基于内容将数据路由到不同的目的地应该相当简单。

第一步是通过源端拦截器将您想要切换到 Flume 头中的数据获取到 Flume 头中(如果头还不可用)。 第二步是在该标头值上使用多路复用通道选择器来将数据切换到备用通道。

例如，假设您希望捕获 HDFS 的所有异常。 在此配置中，您可以看到源`s1`上通过端口 42424 上的 avro 传入的事件。 测试该事件以查看正文是否包含文本“Exception”。 如果是，它会创建一个标题键`exception`(值为`Exception`)。 此标头用于将这些事件切换到通道`c1`，并最终切换到 HDFS。 如果事件与模式不匹配，它将没有`exception`头，并将通过默认选择器传递到通道`c2`，在那里它将通过 AVRO 序列化转发到服务器`foo.example.com`上的端口 12345。

```scala
agent.sources=s1
agent.sources.s1.type=avro
agent.sources.s1.bind=0.0.0.0
agent.sources.s1.port=42424
agent.sources.s1.interceptors=i1
agent.sources.s1.interceptors.i1.type=regex_extractor
agent.sources.s1.interceptors.i1.regex=(Exception)
agent.sources.s1.interceptors.i1.serializers=ex
agent.sources.s1.intercetpros.i1.serializers.ex.name=exception
agent.sources.s1.selector.type=multiplexing
agent.sources.s1.selector.header=exception
agent.sources.s1.selector.mapping.Exception=c1
agent.sources.s1.selector.default=c2
agent.channels=c1 c2
agent.channels.c1.type=memory
agent.channels.c2.type=memory
agent.sinks=k1 k2
agent.sinks.k1.type=hdfs
agent.sinks.k1.channel=c1
agent.sinks.k1.hdfs.path=/logs/exceptions/%y/%M/%d/%H
agent.sinks.k2.type=avro
agent.sinks.k2.channel=c2
agent.sinks.k2.hostname=foo.example.com
agent.sinks.k2.port=12345
```

# 摘要

在本章中，我们介绍了水槽附带的以下各种拦截器：

*   Timestamp：用于添加时间戳头，可能会覆盖已有的时间戳头。
*   主机：用于将 Flume 代理主机名或 IP 添加为事件中的标头。
*   静态：用于添加静态字符串头。
*   正则表达式过滤：用于根据匹配的正则表达式包括或排除事件。
*   正则表达式提取器：用于从匹配的正则表达式标头创建标头。 它对于使用频道选择器进行布线也很有用。
*   Custom：它用于创建您需要的、在其他地方找不到的任何自定义转换。

我们还介绍了使用 Avro Source 和 Sink 对数据流进行分层。

接下来，我们介绍了两个 Log4J Appender，单路径和负载平衡版本，用于与 Java 应用程序直接集成。

最后，我们给出了一个结合使用拦截器和通道选择器来提供路由决策逻辑的示例。

在下一章中，我们将介绍使用 Ganglia 监控 Flume 数据流。