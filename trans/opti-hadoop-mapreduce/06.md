# 第六章。优化地图缩减任务

大多数 MapReduce 程序是为数据分析而编写的，通常需要花费大量时间来完成。许多公司正在采用 Hadoop 对需要完成时间保证的大型数据集进行高级数据分析。效率，尤其是 MapReduce 的输入/输出成本，仍然需要解决才能成功。

在这一章中，我们将讨论一些优化技术，例如使用压缩和使用组合器来提高作业执行。在本章中，您还将学习优化映射器和缩减器代码的基本准则和规则，以及使用和重用对象实例的技术。

本章将涵盖以下主题:

*   使用组合器的好处
*   使用压缩的重要性
*   学习使用合适的可写类型
*   如何巧妙重用类型
*   如何优化映射器和减速器的代码

# 使用组合器

您可以使用 **组合器**来提高整体 MapReduce 性能。组合器相当于局部减少操作，可以有效提高后续全局减少操作的速率。基本上，它用于初步优化和最小化映射器和缩减器之间通过网络传输的键/值对的数量。组合器将使用映射操作处理键/值对输出的中间结果，并且它不影响在`map`和`reduce`函数中编码的转换逻辑。

使用组合器的标准惯例只是将您的减速器功能重新调整为您的组合器。计算逻辑应该是 **交换式** (加法等运算的处理顺序对最终结果没有影响)和 **联想式**(我们应用加法运算的顺序对最终结果没有影响)。

### 注

要获取有关交换和关联属性的更多信息，您可以浏览以下链接:

[http://en.wikipedia.org/wiki/Commutative_property](http://en.wikipedia.org/wiki/Commutative_property)T2】

[http://en.wikipedia.org/wiki/Associative_property](http://en.wikipedia.org/wiki/Associative_property)T2】

实现一个组合器意味着实现一个组合器类。一旦实现并添加了定制类，Map 函数就不会立即写入输出以产生键/值对的中间结果。相反，它们将被收集到列表中，每个键对应一个值列表。组合器类将以键/值对的形式输出键和相应的值列表。当组合器缓冲区达到一定数量的键/值对时，缓冲区中的数据将被清除并传输到减少功能。

### 类型

为作业调用您的`Combiner`定制类类似于如何设置映射和缩减类:

```
job.setCombinerClass(MyCombine.class);
```

下面的截图显示了使用 Combiners 时应该关注的 Hadoop 计数器:

![Using Combiners](graphics/5655OS_06_01.jpg)

在这个截图中，你可以观察**组合输入记录**和**组合输出记录的记录数，**为 **0** ，因为作业没有实现任何组合器类。因此**减少输入记录**的数量与**映射输出记录**相同。下面的截图显示了组合器在实现后的效果:

![Using Combiners](graphics/5655OS_06_02.jpg)

在这个截图中，注意**合并输入记录**、**合并输出记录**的记录数，**减少输入记录**、**映射输出记录**的记录数。您将观察到实现合并器减少了传输到减少功能的数据量。

与上图相比，由于使用了组合器功能，该作业的组合记录数量有所增加。减少输入数据量已降至 **685，760** ，而最初为 **10，485，760** 。在非常大的数据环境中，使用 Combiners 是提高 MapReduce 作业整体性能的有效方法。

下面的代码片段说明了从 MapReduce 作业中提取的自定义组合器类:

![Using Combiners](graphics/5655OS_06_03.jpg)

可以看到，`Combine`类实现了`Reducer`接口，像一个 reducer 函数，会用地图输出的多个值调用。这个类用自己的代码重写`reduce()`方法。第 12 行和第 23 行之间的示例代码遍历由`mapper`函数传输的值列表，如果当前键与前一个键不同，它调用 `collect()`方法输出结果。

# 使用压缩

压缩减少了从底层存储系统(HDFS)读取或写入的字节数。压缩提高了网络带宽和磁盘空间的效率。在 Hadoop 中使用数据压缩非常重要，尤其是在非常大的数据环境和密集工作负载下。在这种情况下，输入/输出操作和网络数据传输需要相当长的时间才能完成。而且洗牌合并过程也会面临巨大的 I/O 压力。

由于磁盘 I/O 和网络带宽是 Hadoop 中宝贵的资源，数据压缩有助于节省这些资源，将 I/O 磁盘和网络传输降到最低。实现更高的性能和节省这些资源并不是免费的，尽管它是在压缩和解压缩操作时以低 CPU 成本完成的。

每当输入/输出磁盘或网络流量影响您的 MapReduce 作业性能时，您可以通过在任何 MapReduce 阶段启用压缩来改善端到端处理时间并减少输入/输出和网络流量。

### 注

压缩地图输出将始终有助于减少地图之间的网络流量并减少任务。

压缩可以在 MapReduce 作业的任何阶段启用，如下图所示:

![Using compression](graphics/5655OS_06_04.jpg)

*   **Compress Input**: This should be considered in a very large data context that you plan to process repeatedly. Therefore, you do not need to explicitly specify a codec to use. Hadoop will automatically check for the extension of your files and if it detects an appropriate extension, it will use the appropriate codec to compress and decompress your files. Otherwise, no compression codec will be used by Hadoop.

    ### 注

    使用复制时，压缩输入文件可以节省存储空间并加快数据传输。要压缩输入数据，您应该使用可拆分的算法，如`bzip2`，或者使用`SequenceFile`格式的`zlib`。

*   **Compress Mapper output**: Compression should be considered at this stage if your map tasks output a large amount of intermediate data. This will significantly improve the internal shuffle process, which is the most resource-consuming Hadoop process. You should always consider using compression if you observe slow network transfers due to large data volumes. To compress Mapper outputs, use faster codecs such as `LZO`, `LZ4`, or `Snappy`.

    ### 注

    **Limpel-Zif-Oberhumer**(**LZO**)是 Hadoop 中常用的压缩编解码器，用于压缩数据。它的设计是为了跟上硬盘的读取速度，因此将速度视为优先事项，而不是压缩率。与 **gzip** 编解码器相比，它的压缩速度快了大约五倍，解压缩速度快了两倍。使用 LZO 压缩的文件比使用 gzip 压缩的相同文件大 50%，但仍然比原始文件小 25-50%，这有利于提高性能，并且映射阶段完成的速度大约快四倍。

*   **Compress Reducer output**: Enabling compression at this stage will reduce the amount of data to be stored and therefore the required disk space. This is also useful if you chain MapReduce jobs together while the input files of the second job are already compressed.

    ### 注

    压缩 reduce输出应考虑用于存储和/或归档、更好的写入速度或 MapReduce 作业。要压缩 Reducer 输出，请使用标准实用程序，如用于数据交换的`gzip`或`bzip2`，以及用于链接作业的更快编解码器。

下面的截图显示了在地图输出文件上启用压缩之前，MapReduce 作业写入和读取的字节数:

![Using compression](graphics/5655OS_06_05.jpg)

为了启用地图输出文件压缩，您可以如下更改这些配置参数(在`mapred-site.xml`文件中):

![Using compression](graphics/5655OS_06_06.jpg)

默认情况下，`mapred.compress.map.output`值设置为`false`，`mapred.output.compression.type`值设置为`RECORD`。将该值更改为`BLOCK`可提高压缩比。

对地图输出文件启用压缩后，与上图( **858** )相比，reduce 函数( **268** )读取的字节数大幅减少，如下图所示:

![Using compression](graphics/5655OS_06_07.jpg)

为了在 Hadoop 中启用压缩，您可以设置如下表所示的配置参数:

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

参数

 | 

缺省值

 | 

阶段

 | 

推荐

 |
| --- | --- | --- | --- |
| `io.compression.codec` | `DefaultCodec` | 输入压缩 | Hadoop 使用文件扩展名来确定是否支持压缩编解码器 |
| `mapreduce.map.output.compress` | `false` | 映射器输出 | 将该参数设置为`true`以启用压缩 |
| `mapreduce.map.output.compress.codec` | `DefaultCodec` | 映射器输出 | 在此阶段使用`LZO`、`LZ4`或`Snappy`编解码器压缩数据 |
| `mapreduce.output.fileoutputformat.compress` | `false` | 减速器输出 | 将该参数设置为`true`以启用压缩 |
| `mapreduce.output.fileoutputformat.compress.codec` | `DefaultCodec` | 减速器输出 | 使用标准工具/编解码器，如`gzip`或`bzip2` |
| `mapreduce.output.fileoutputformat.compress.type` | `RECORD` | 减速器输出 | 用于顺序文件输出的压缩类型:`NONE`和`BLOCK` |

# 使用适当的可写类型

Hadoop 使用自定义数据类型序列化/RPC 机制，并定义了自己的 *box* 类型类。这些类用于操作字符串(`Text`)、整数(`IntWritable`)等等，它们实现了定义反序列化协议的`Writable`类。

因此，Hadoop 中的所有`values`都是`Writable`类型对象，所有`keys`都是`WritableComparable`的实例，定义了排序顺序，因为它们需要比较。

可写对象是可变的，并且更加紧凑，因为不需要存储元信息(类名、字段、超类等)，直接的随机访问提供了更高的性能。由于二进制`Writable`类型将占用更少的空间，这将减少映射或组合函数写入的中间数据的大小。减少中间数据可以通过减少网络传输和输入/输出磁盘所需的存储空间来大幅提高性能。

在代码中使用适当的可写类型将有助于提高 MapReduce 作业的整体性能。这主要是通过使用`Text`类型而不是`String`类型来消除串分裂的时间来完成的。此外，使用`VIntWritable`或`VLongWritable`有时比使用常规的`int`和`long`原始 Java 数据类型更快。

在 Shuffle 和排序阶段，比较中间键可能是一个瓶颈，Hadoop 可能会在这个阶段花费时间。实现新的比较机制可以提高您的 MapReduce 性能。有两种方法可以比较您的密钥:

*   通过实现`org.apache.hadoop.io.WritableComparable`接口
*   通过实现`RawComparator`接口

根据我们的经验，使用`RawComparator`实现原始字节比较提高了 MapReduce 作业的整体性能，并且比`WritableComparable`有优势。

`WritableComparable`类的典型实现看起来像下面的代码片段:

![Using appropriate Writable types](graphics/5655OS_06_08.jpg)

要实现`RawComparator`，还可以扩展`WritableComparator`类，实现`RawComparator`。以下代码片段说明了 `WritableComparator`类的典型实现:

![Using appropriate Writable types](graphics/5655OS_06_09.jpg)

### 注

扩展 `WritableComparator`类允许您使用该类的继承方法来操作您的中间 MapReduce 键。

从`WritableComparator`继承的 `readInt()`方法将 4 个连续的字节转换成一个原始的 Java `int`(即 4 个字节)。

### 类型

要连接您的`RawComparator`自定义类实现，请按如下方式设置其排序比较器类:

```
job.setSortComparatorClass(MyClassComparator.class);
```

根据您想要处理的数据，您可能需要定义如何将您的数据文件读入 Mappers 实例。Hadoop 允许您通过实现`InputFormat`接口来定义自己的数据格式，并附带了它的几种实现。

### 注

`InputFormat`类是 Hadoop 框架的基本类之一，它负责定义两个主要的东西:`InputSplit`和`RecordReader`。

一个`InputFormat`类描述了如何向映射器呈现数据以及数据的来源。`InputSplit`界面定义了单个地图任务的大小及其执行服务器。`RecordReader`界面负责从输入文件中读取记录，并将它们(作为键/值对)提交给映射器。`InputFormat`类的另一项重要工作是将输入文件源分割成片段，由`FileInputSplit`实例表示。这些片段被用作各个映射器的输入。为了提高作业的性能，此过程必须足够快且便宜(它应该使用最少的 CPU、I/O 存储和网络资源)。

### 类型

创建自己的`InputFormat`类时，最好子类化`FileInputFormat`类而不是直接实现`InputFormat`。

# 智能重用类型

通常，Hadoop 问题是由某种形式的内存管理不善引起的，节点不会突然出现故障，而是会随着输入/输出设备的损坏而变慢。Hadoop 有许多选项可以在几个粒度级别上控制内存分配和使用，但它不检查这些选项。因此，一台计算机上所有守护程序的组合堆大小都有可能超过物理内存量。

每个 Java 进程本身都有一个配置的最大堆大小。根据 JVM 堆大小、操作系统限制或物理内存是否首先耗尽，这将分别导致内存不足错误、JVM 中止或严重交换。

你应该注意内存管理。应该删除所有不必要的已分配内存资源，以最大化 MapReduce 作业的内存空间。

重用类型是一种技术，用于最小化资源使用，如中央处理器和内存空间。当您处理数百万条数据记录时，重用现有实例总是比创建新实例更便宜。MapReduce 作业中最简单的可重用性是使用现有的 Hadoop 可写类型，这在大多数情况下都是可能的。

初学者在编写`map`或`reduce`函数时最常见的错误之一是为每个输出分配一个新的对象，这通常是在`for`或`foreach`循环中完成的，这可能会创建数千或数百万个新的`Writable`实例。这些实例具有非常短的 TTL(生存时间)，并强制 Java 的垃圾收集器执行大量工作来处理它们所需的所有已分配内存。

下面的代码片段显示了一个映射器函数，它为每个输出分配一个新的`Writable`实例(您应该避免这样编码)。

![Reusing types smartly](graphics/5655OS_06_10.jpg)

为了检测您是否在为不必要的对象分配资源上花费了时间，您应该检查任务日志并分析垃圾收集器活动。如果它代表了大量的时间和频繁，这意味着您应该检查您的代码，并通过消除不必要的创建新对象来增强它。

这是因为如果内存不足，那么只要超过某个内存阈值，并且垃圾收集器必须更频繁地运行，创建新对象就会存储在堆内存中。

### 注

重用可写变量理论上更好，但基于阿姆达尔定律([http://en.wikipedia.org/wiki/Amdahl%27s_law](http://en.wikipedia.org/wiki/Amdahl%27s_law))，这种改进可能并不明显。

日志通常用于诊断问题。通常，表示问题的那一行被埋在成千上万行中。挑出相关的线是一项漫长而又挑剔的任务。要更详细地检查 MapReduce 任务日志，应该在`mapred-site.xml`配置文件中设置 JVM 内存参数，如下表所示:

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

参数

 | 

缺省值

 | 

推荐

 |
| --- | --- | --- |
| `mapred.child.java.opts` | `-Xmx200m` | 添加:`-verbose:gc -XX:+PrintGCDetails` |

下面的代码片段展示了一种更好的方法来发现重用`Writable`变量的好处:

![Reusing types smartly](graphics/5655OS_06_11.jpg)

JVM 重用是一种针对多个任务重用 JVM 的优化技术。如果启用，一个 JVM 可以顺序执行多个任务。您可以通过更改`mapred-site.xml`配置文件中的适当参数来启用 JVM 重用，如下表所示:

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

参数

 | 

缺省值

 | 

推荐

 |
| --- | --- | --- |
| `mapred.job.reuse.jvm.num.tasks` | `1` | 更改此变量以运行所需数量的任务(例如，`2`运行两个任务)。如果将该变量设置为`-1`，则 JVM 可以执行的任务数量不受限制。 |

# 优化映射器和缩减器代码

在细节中优化 MapReduce 代码端性能超出了本书的范围。在本节中，我们将提供一个基本指南，其中包含一些有助于提高 MapReduce 作业性能的规则。

Hadoop 的一个重要特性是所有数据都在一个被称为**记录**的单元中处理。虽然记录的大小几乎相同，但理论上，处理这些记录的时间应该是相同的。然而，在实践中，任务内记录的处理时间变化很大，当从存储器中读取记录、处理记录或将记录写入存储器时，可能会出现缓慢。此外，在实践中，还有两个因素可能会影响映射器或缩减器的性能:输入/输出访问时间和溢出，以及大量输入/输出请求导致的开销等待时间。

### 注

效率是可测量的，由产出与投入的比率定量确定。

MapReduce 提供了易用性，而程序员只使用 Map 和 Reduce 函数定义他的工作，而不必指定他的工作在节点间的物理分布。因此，Hadoop 提供了一个固定的数据流来执行 MapReduce 作业。这就是为什么许多复杂的算法很难仅在 MapReduce 作业中使用映射器和缩减器来实现。此外，由于 MapReduce 的数据流最初被设计为读取单个输入并生成单个输出，因此一些需要多个输入的算法没有得到很好的支持。

优化一个 MapReduce 作业意味着:

*   在更短的时间内获得相同的输出
*   用更少的资源在相同的时间获得相同的产出
*   用相同的资源在相同的时间获得更多的产出

在任何编程语言中，分解代码都是优化的第一步。如果您运行多个作业来处理相同的输入数据，则可能有机会将它们重写为更少的作业。此外，在编写映射器或减速器功能代码时，您应该选择最高效的底层算法，这将有助于加快您的工作速度，否则您可能需要处理缓慢和/o r 不良性能。因此，代码中的低效率会降低您的 MapReduce 作业速度。

### 类型

使用以下命令检查作业跟踪器的当前日志记录级别:

```
hadoop daemonlog -getlevel {HadoopMachineName}:50030 org.apache.hadoop.mapred.JobTracker
```

为作业跟踪器设置 Hadoop 日志调试级别，如下所示:

```
hadoop daemonlog -setlevel {HadoopMachineName}:50030 org.apache.hadoop.mapred.JobTracker DEBUG
```

第二步是确定执行 MapReduce 作业时是否有问题。当所有映射器/缩减器看到此作业的失败任务数为零时，它们应该成功终止。如果这个数字非零，基本上你的程序有问题。如果数量少(两个或三个)，节点可能不稳定。

### 注

有时候不仅仅是你的工作导致了问题，还有其他原因可能导致了问题。

有些算法在处理过程中需要全局状态信息，而 MapReduce 在执行过程中不处理状态信息。MapReduce 迭代读取数据，并在每次迭代中将中间结果物化在本地磁盘上，这需要大量的 I/O 操作。如果需要实现这样的算法，应该考虑使用第三方工具，比如halopp([http://code.google.com/p/haloop/](http://code.google.com/p/haloop/))或者Twister([http://www.iterativemapreduce.org/](http://www.iterativemapreduce.org/))。

您可以通过减少 Hadoop 分发繁重应用程序所需的分发时间和网络带宽来增强您的 MapReduce 作业。请记住，MapReduce 框架假设了一个计算密集型应用程序，因为计算任务需要传输到集群中计划并行运行的每个节点。跨集群节点传输具有非常大的代码占用空间的应用程序将花费大量时间，这将完全耗尽并行执行多个实例所带来的吞吐量优势。

### 注

尝试在所有节点上预安装计算任务；它将完全避免任务分配的需要和相关的时间损失。

请记住，MapReduce 旨在处理非常大的数据量作为输入记录。如果由于某种原因，您的映射器无法读取输入记录，那么每次失败时终止任务将会适得其反，因为最终结果将保持不变，映射器任务仍然会失败。

为了防止这种情况，您应该在阅读器中处理输入错误并报告该错误(有时您需要创建一个自定义`OutputFormat`类)，以便它可以被管理员跟踪或在调试会话时跟踪。

### 类型

如果您的应用程序允许记录跳过，Hadoop 将为您提供一个通过`SkipBadRecords`类跳过记录的功能:

```
setMapperMaxSkipRecords(Configuration conf,long maxSkipRecs)
setReducerMaxSkipGroups(Configuration conf,long maxSkipGrps)
```

# 总结

在本章中，我们了解了 MapReduce Combiners，以及它们如何帮助改善整体执行作业时间。此外，我们还介绍了为什么使用压缩很重要，尤其是在大数据量环境中。

然后，我们介绍了 Java 代码端优化，并学习了如何选择合适的可写类型以及如何智能地重用这些类型。我们还学习了`WritableComparator`和`RawComparator`自定义类的实现。

在最后一节中，我们介绍了基本的指导原则以及一些调整 Hadoop 配置和提高其性能的规则。

在下一章中，我们将了解更多关于 MapReduce 优化的最佳实践。继续读！