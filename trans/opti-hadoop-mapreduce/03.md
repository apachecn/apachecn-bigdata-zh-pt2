# 第三章检测系统瓶颈

如何知道 Hadoop MapReduce 作业是否以最佳方式执行其工作？ 在我们的咨询实践中，我们收到的与性能相关的最常见请求之一是找出执行特定作业需要很长时间的原因，并对瓶颈事件进行故障排除。

在[章](01.html "Chapter 1. Understanding Hadoop MapReduce")、*了解 Hadoop MapReduce*和[章](02.html "Chapter 2. An Overview of the Hadoop Parameters")、*Hadoop 参数概述*中，我们了解了可能影响 Hadoop MapReduce 性能的因素和 Hadoop MapReduce 公共参数的设置。 在本章中，我们将继续我们的旅程，学习如何检测潜在的系统瓶颈。

本章介绍性能优化过程、在任何优化作业之前创建基准的重要性，以及如何使用此基准优化集群。 您还将学习如何识别资源瓶颈以及如何打破这些瓶颈。

在本章中，我们将介绍以下内容：

*   介绍性能调优过程
*   创建性能基准
*   Hadoop 集群调优方法
*   确定系统资源瓶颈

# 性能调整

性能调优的基本目标是确保给定集群配置中的所有可用资源(CPU、RAM、I/O 和网络)都可用于特定作业，并以平衡的方式使用。

Hadoop MapReduce 资源分为计算、内存、网络带宽和输入/输出存储等类别。 如果这些资源中的任何一个性能不佳，这将影响 Hadoop 的性能，这可能会导致您的作业运行缓慢。 因此，调优 Hadoop MapReduce 性能就是在 Hadoop 集群上获得均衡的资源，而不仅仅是调优一个或多个变量。

简而言之，调优 Hadoop MapReduce 作业流程由多个分析组成，这些分析调查 Hadoop 指标和指示符，以便了解执行时间、使用的内存量以及要读取或存储在本地文件系统中的字节数，等等。

Hadoop 性能调优是一个迭代过程。 您启动一个作业，然后分析 Hadoop 计数器，调整它们，然后重新运行该作业。 然后重复此过程，直到达到 Hadoop 群集的最终性能。 以下步骤描述了此过程：

1.  Create a baseline, as you first need to evaluate the overall system performance. You will run your job the first time using the default configuration settings of your Hadoop cluster. This will be your baseline.

    拥有此基线后，您将开始调优变量值以最佳地执行作业。 因此，我们可以说，性能调优是测量和分析时间消耗情况的主要手段。

2.  您将分析 Hadoop 计数器，修改和调整一些配置设置，然后重新运行该作业。 将结果与基线进行比较。 分析完成后，您可以查看结果并接受或拒绝推论。
3.  重复步骤 2，直到作业的执行时间最短。

下图说明了 Hadoop 性能调整过程：

![Performance tuning](graphics/5655OS_03_01.jpg)

# 创建绩效基准

让我们首先为我们的系统创建一个性能基准。 在创建基线时，您应该保留 Hadoop 的默认配置设置，并使用 TeraSort 基准测试工具，该工具是随 Hadoop 分发包提供的示例 JAR 文件的一部分。 TeraSort 被认为是比较 Hadoop 性能的行业标准基准。 此基准测试工具尝试使用整个 Hadoop 群集尽可能快地对 1 TB 数据进行排序，并分为三个主要模块：

*   **TeraGen**：此模块用于生成所需大小的文件作为输入，通常范围在 500 GB 到 3TB 之间。 一旦 TeraGen 生成输入数据，它就可以在文件大小相同的所有运行中使用。
*   **TeraSort**：此模块将跨 Hadoop 集群对输入文件进行排序。 TeraSort 在计算、网络带宽和 I/O 响应方面强调了 Hadoop 集群在两层(MapReduce 和 HDFS)上的作用。 排序后，将创建单个简化任务，以检查排序阶段的输出是否有效。
*   **TeraValidation**：此模块用于提高准确性并验证排序后的数据。

为了运行 TeraSort 基准测试工具并获得基线，您首先需要生成将按 TeraSort 排序的样例输入数据。 使用以下命令行指定文件大小(`104857600`=10 GB)和输出 DFS 目录(`/data/input`)，运行 TeraGen 以生成 10 GB 大小的文件(根据您的群集容量，您可以生成更大的文件大小，最高可达 3 TB)：

```
hadoop jar $HADOOP_PREFIX/hadoop-*examples*.jar teragen 104857600 /data/input

```

### 备注

`/data/input`HDFS 目录必须为空，否则将出现 Java 异常错误。 如果不是空的，可以使用以下命令行清除此目录：

```
hadoop dfs -rmr /data/input

```

要检查样例数据文件是否已正确生成，请打开 Hadoop DFS 主页(`http://machinename:50070/dfshealth.jsp`)并检查**DFS Used**行，该行应该反映生成的数据的大小。 您还可以浏览 DFS 文件系统中的`/data/input`目录，该目录应该包含所有生成的文件(`part-0000`-`part-00*`)。

生成输入数据后，使用以下命令行运行`TeraSort`，该命令行指定输入和输出数据文件夹：

```
hadoop jar $HADOOP_PREFIX/hadoop-*examples*.jar terasort /data/input /d
ata/output

```

### 备注

优化和调整群集的唯一真正方法是分析计数器，更改设置的配置，重新运行 MapReduce 作业，然后返回更改设置并重新运行作业，直到您将完成时间降低到可能的最低值。

TeraSort 作业完成后，您将获得性能基准。 现在我们可以转到迭代步骤(在上一节中讨论)，然后分析这些设置。

为了说明如何使用这个性能基准，让我们假设我们想要在一个三节点 Hadoop 集群上处理一个 10 GB 的文件(每个节点有一个带四个核心的 CPU、4 GB RAM 和 40 GB 硬盘空间)。 根据默认设置(在下表中报告)，此作业耗时 4 分 3 秒。

这是一个具有中等数据大小上下文的轻型 Hadoop 集群。 因此，可以按如下方式配置群集：

*   复制因子可以降低到 2。
*   数据块大小最高可增加到 128 MB。
*   `io.sort.factor`参数取决于节点上的可用内存。 每个节点有 4 GB 的内存；因此，我们可以为中间地图数据提供更多内存。
*   `io.sort.mb`值应该是*io.sort.factor*10，即 35*10=350MB*，这是允许映射中间数据的大小。
*   可以将`mapred.tasktracker.map.tasks.maximum`和`mapred.tasktracker.reduce.tasks.maximum`的值设置为 CPU 核数减 1。 因此，该值应为*4-1=3*。
*   建议将`mapred.reduce.tasks`的值设置在集群容量的 50%到 99%之间，这样所有的 Reduce 任务都可以在一次浪潮中完成。 因此，此参数可以设置为*0.95*3(节点)*3=8.55*个减速器插槽，向下舍入为 8。

默认值`mapred.child.java.opts`可以增加到 500 MB，以允许更多内存用于映射和减少器任务。 但是，这不应超过节点上的可用 RAM。 因此，您可以使用以下公式设置此值：*(mapred.tasktracker.map.tasks.max+mapred.tasktracker.duce e.tasks.max)*要分配的内存(MB)<可用 RAM-保留内存，即(3+3)*500<4096-350*(保留的中间映射输出)。

现在，我们再次运行相同的 MapReduce 作业，报告配置的设置，并将结果与基线的结果进行比较。 我们可以选择接受或拒绝调整结果，然后再次重新调整设置，直到我们对结果满意为止。

下表总结了所有这些设置值：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

Hadoop 参数

 | 

基数 / 起点 / 底线 / 基线

 | 

调谐 1

 | 

调谐 2

 | 

调谐 3

 |
| --- | --- | --- | --- | --- |
| `dfs.replication` | 3. | 2 个 |   |   |
| `dfs.block.size` | 67108864 | 134217728 |   |   |
| `dfs.namenode.handler.count` | 10 个 | 20 个 |   |   |
| `dfs.datanode.handler.count` | 3. | 5. |   |   |
| `io.sort.factor` | 10 个 | 35 岁 |   |   |
| `io.sort.mb` | 100 个 | 350 |   |   |
| `mapred.tasktracker.map.tasks.maximum` | 2 个 | 3. |   |   |
| `mapred.map.tasks` | 2 个 | 2 个 |   |   |
| `mapred.reduce.tasks` | 1. | 8 个 |   |   |
| `mapred.tasktracker.reduce.tasks.maximum` | 2 个 | 3. |   |   |
| `mapred.reduce.parallel.copies` | 5. | 5. |   |   |
| `mapred.job.reduce.input.buffer.percent` | 0 | 0 |   |   |
| `mapred.child.java.opts` | -Xmx200m | -Xmx500m |   |   |
| … |   |   |   |   |
| 输入数据大小 | 10 GB | 10 GB |   |   |
| 群集的节点号 | 3. | 3. |   |   |
| 作业执行时间(秒) | 二百四十三 | 185 |   |   |
| 对基线的改进(百分比) |   | 23.86% |   |   |

# 确定资源瓶颈

通常，当系统的一个资源消耗的时间超过完成其任务所需的时间，并迫使其他资源等待，从而降低整体系统性能时，就会出现瓶颈。

在深入调优 Hadoop 集群之前，最好确保集群是稳定的，并且 MapReduce 作业是可操作的。 我们建议您验证群集的硬件组件是否配置正确，如有必要，请将 Hadoop 堆栈的任何软件组件升级到最新的稳定版本。 您还可以执行 MapReduce 作业(如 TeraSort 或 PI Estimator)来对集群施加压力。 这是获得健康和优化的 Hadoop 集群的非常重要的一步。

一旦您的集群硬件和软件组件得到了良好的配置和更新，您就需要创建一个基准性能压力测试。 为了给 Hadoop 集群施加压力，您可以使用 Hadoop 微基准测试，比如 TeraSort、TestDFSIO、NNBench 或 MRBench。 所有这些基准测试都是 Hadoop 发行包的一部分。

但是，请记住，MapReduce 作业实际上是一个具有多个阶段的管道，每个阶段需要不同类型的资源。 下图描述了 Hadoop 完成 MapReduce 作业所需的主要资源(CPU、RAM、I/O 和网络带宽)，这些资源可能会造成潜在的资源瓶颈。

![Identifying resource bottlenecks](graphics/5655OS_03_02.jpg)

## 识别 RAM 瓶颈

RAM(内存)是一个潜在的瓶颈来源，可能会对 MapReduce 作业性能产生重大影响。 每个节点上的可用内存量应该足以处理要处理的作业的需求。 您需要确保正确配置和设置集群节点的内存。 否则，在工作负载密集的上下文中，Map 和 Reduce 任务可能会启动，但会立即失败。 此外，当 Hadoop 没有足够的内存来处理数据时，它将使用系统存储来存储其数据，内存和存储之间的这些交换可能会很耗时，并会降低系统速度。

为了识别潜在的内存瓶颈，您应该使用监控工具(如 Ganglia、`vmstat`)突出显示交换内存的使用情况。 这将帮助您确定 map 和 Reduce 任务是否有足够的内存来完成其工作。 否则，您可能应该扩展节点的物理内存或调整映射器和减少器的数量。

以下屏幕截图显示了`vmstat`输出报告，其中显示了交换到磁盘的内存量(`so`列)和从磁盘交换的内存量(`si`列)：

![Identifying RAM bottlenecks](graphics/5655OS_03_03.jpg)

在[章](04.html "Chapter 4. Identifying Resource Weaknesses")，*识别资源弱点*中，您将了解如何根据每个节点上的物理内存配置映射的数量和减少任务。

## 识别 CPU 瓶颈

CPU 是在 Map 和 Reduce 计算阶段处理数据时的关键资源。 密集的 CPU 活动可能是`map`和/或`reduce`用户函数代码中密集计算的结果。 这种高 CPU利用率可能是一个潜在的瓶颈。 此外，如果在处理数据之前需要等待其他资源馈送数据，则 CPU 通常可能处于空闲状态。 这通常是由于 map 和 Reduce 任务配置错误以及 Hadoop 框架未充分利用 CPU 资源造成的。 CPU 瓶颈的症状并不难识别。 通常，处理器负载(时间)通常超过 90%；在多处理器系统上，总处理器负载(时间)超过 50%。 但是，这些症状并不总是表明处理器有问题。

要确定您的节点是否处理非常高的 CPU 活动，您应该使用监视工具检查处理器实际运行的所有进程和线程。 然后，您应该确定是否有个特定进程独占 CPU，并了解为什么会这样做。 调优 map 和 Reduce 任务的数量可能会解决瓶颈，作为最后的手段，您可能需要升级到速度更快的处理器或添加额外的处理器，这对整个 MapReduce 作业是有好处的。

## 确定存储瓶颈

存储 I/O 是第二个最常见的瓶颈来源，不幸的是，Hadoop 在 MapReduce 管道过程的许多阶段都需要该资源。 存储资源会降低 MapReduce 作业的性能，成为执行流水线各个阶段的瓶颈。 在执行任何存储调整操作之前，建议对您的存储进行基准测试，以了解其 I/O 吞吐量能力。 您可以通过运行 Hadoop HDFS 基准测试 TestDFSIO 来实现这一点，这是一个针对 HDFS 的读/写测试。 此外，要运行分布式基准测试，您可以使用DFSCIOTest，它是`libhdfs`的 I/O 分布式基准测试。

存储瓶颈表现为磁盘活动率持续高于 85%。 但这种症状也可能是内存或 CPU 瓶颈的结果，看起来像是磁盘瓶颈。 这就是为什么在尝试识别磁盘瓶颈之前，您应该首先检查是否存在任何内存或 CPU 瓶颈。

使用 TestDFSIO 基准测试工具将帮助您了解集群的 NameNode 和 DataNode 存储有多快。 下图显示了典型的 TestDFSIO 输出日志：

![Identifying storage bottlenecks](graphics/5655OS_03_04.jpg)

要使用 TestDFSIO 启动读/写基准测试，您可以使用以下命令行，该命令行写入/读取10 个文件，每个文件大小为 1000MB。

```
hadoop jar hadoop-test.jar TestDFSIO -write -nrFiles 10 -fileSize 1000
hadoop jar hadoop-test.jar TestDFSIO -read -nrFiles 10 -fileSize 1000

```

因此，使用 TestDFSIO 的 log信息输出，可以使用以下公式计算存储吞吐量：

*总读取吞吐量和总写入吞吐量=文件数*吞吐量(MB/秒)*。

在[章](04.html "Chapter 4. Identifying Resource Weaknesses")，*识别资源弱点*中，您将了解如何确定给定节点的存储容量。

## 识别网络带宽瓶颈

网络带宽也可能是一个可能的瓶颈源。 通常，当您必须通过网络传输大量数据时，就会出现此瓶颈。 在 Hadoop 上下文中，当存在大量数据时，就会出现这个瓶颈。 当 Reduce 任务在混洗阶段从 MAP 任务拉取数据时，以及作业将最终结果输出到 HDFS 中时，就会出现高网络利用率。

对于存储系统，建议对 Hadoop 群集施加压力，以了解您的网络带宽能力，并确保网络利用率在用于特定作业时不会成为瓶颈。 需要持续监控网络带宽，以便能够确定您的数据是否可以在集群的节点之间高效传输。

### 提示

要分析系统的性能，您还可以使用 Linux OS 实用程序，如`dstat`、`top`、`htop`、`iotop`、`vmstat`、`iostat`、`sar`或`netstat`，它们有助于捕获系统级性能统计信息。 然后使用收集到的数据研究 Hadoop 作业如何利用集群的不同资源，以及哪些资源会造成瓶颈或处于争用状态。

要识别和深入分析由软件和/或硬件事件引起的潜在性能瓶颈，您还可以使用 Linux 分析器，如`perf`或`strace`。

网络性能分析是其他监控工作的后续工作。 通常，您应该从检查您的网络硬件开始，包括电缆、集线器、交换机等外部元素。 然后，确保您的网络组件使用的是最新的网络适配器和最新的设备驱动程序版本。 您还应该检查网络的配置，并确保将其设置为尽可能高和最宽的带宽。

要识别潜在的网络带宽瓶颈，您应该监视和检查网络数据和中断率(通过网络接口卡发送和接收的字节数)。 如果数据速率接近或等于可用带宽的八分之一，则可以推断这可能是网络过载的迹象。 此外，较高的中断率意味着您的系统因网络流量的中断而超载。

### 提示

您可以使用`dstat`作为`dstat --nf`来显示数据速率，使用`dstat -i`或`dstat -if`来显示中断速率，来检查网络流量数据和中断速率。

# 摘要

在本章中，我们介绍了性能调优过程周期，并了解了 Hadoop 计数器。 我们介绍了 TeraSort 基准测试及其 TeraGen 模块，并学习了如何生成性能基准，该基准将在调优 Hadoop 集群时用作参考。 我们还学习了通过一个三节点 Hadoop 集群示例来优化 Hadoop 集群的方法，并建议调整一些设置参数以提高集群的性能。

然后，我们继续讨论资源瓶颈，以及每个 MapReduce 阶段都涉及哪些组件，或者哪些组件可能是瓶颈的根源。 对于每个组件(CPU、RAM、存储和网络带宽)，我们了解了如何识别系统瓶颈，并提出建议试图消除它们。

在下一章中，我们将学习如何识别 Hadoop 集群资源弱点以及如何正确配置 Hadoop 集群。 继续读！