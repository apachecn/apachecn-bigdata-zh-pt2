# 四、使用 Impala 和 Kudu 的高性能数据分析

Impala 是 Kudu 默认的 MPP SQL 引擎。Impala 允许您使用 SQL 与 Kudu 进行交互。如果您有使用 SQL 和存储引擎紧密集成的传统关系数据库的经验，您可能会发现 Kudu 和 Impala 相互解耦并不常见。Impala 旨在与其他存储引擎(如 HDFS、HBase 和 S3)一起工作，而不仅仅是 Kudu。将其他 SQL 引擎如 Apache Drill (DRILL-4241)和 Hive (HIVE-12971)与 Kudu 集成的工作也在进行中。在开源社区中，分离存储、SQL 和处理引擎是很常见的。

Impala-Kudu 的整合非常成功，但仍有工作要做。虽然它在性能和可伸缩性方面达到或超过了传统的数据仓库平台，但 Impala-Kudu 仍然缺乏大多数传统数据仓库平台中的一些企业特性。Kudu 是一个年轻的项目。我们将在本章后面讨论其中的一些限制。

## 主关键字

每个 Kudu 表都需要有一个主键。创建 Kudu 表时，必须首先列出用作主键的一列或多列。Kudu 的主键是作为聚集索引实现的。使用聚集索引，行以与索引相同的顺序物理存储在平板中。还要注意，Kudu 没有自动递增特性，所以在向 Kudu 表中插入行时，必须包含唯一的主键值。如果没有主键值，可以使用 Impala 内置的 uuid()函数或者更高效的生成唯一值的方法。

## 数据类型

和其他关系数据库一样，Kudu 支持各种数据类型(表 [4-1](#Tab1) )。

您可能会注意到 Kudu 不支持 decimal 数据类型。这是 Kudu 的一个关键限制。float 和 double 数据类型仅存储非常接近的值，而不是 IEEE 754 规范中定义的精确值。 [<sup>我</sup>](#Sec22)

表 4-1

List of Data Types, with Available and Default Encoding

<colgroup><col align="left"> <col align="left"> <col align="left"></colgroup> 
| 数据类型 | 编码 | 默认 |
| :-- | :-- | :-- |
| 布尔 | 普通，游程长度 | 运行长度 |
| 8 位有符号整数 | 普通、位洗牌、游程长度 | 比特洗牌 |
| 16 位有符号整数 | 普通、位洗牌、游程长度 | 比特洗牌 |
| 32 位有符号整数 | 普通、位洗牌、游程长度 | 比特洗牌 |
| 64 位有符号整数 | 普通、位洗牌、游程长度 | 比特洗牌 |
| unixtime_micros(自 Unix 纪元以来的 64 位微秒) | 普通、位洗牌、游程长度 | 比特洗牌 |
| 单精度(32 位)IEEE-754 浮点数 | 普通，位图 | 位混洗 |
| 双精度(64 位)IEEE-754 浮点数 | 普通，位图 | 比特洗牌 |
| UTF-8 编码字符串(未压缩时最大 64KB) | 普通，前缀，字典 | 词典 |
| 二进制(最多 64KB 未压缩) | 普通，前缀，字典 | 词典 |

因此，行为 float 和 double 不适合存储财务数据。在撰写本文时，对十进制数据类型的支持仍在开发中(Apache Kudu 1.5 / CDH 5.13)。更多详情请查看 KUDU-721。周围有各种各样的工作。您可以将财务数据存储为 string，然后在每次需要读取数据时使用 Impala 将值转换为 decimal。因为 Parquet 支持小数，所以另一个解决方法是对事实表使用 Parquet，对维度表使用 Kudu。Kudu 提交者正在致力于增加十进制支持，并且可能会包含在 Kudu 的新版本中。

如表 [4-1](#Tab1) 所示，根据列的类型，Kudu 列可以使用不同的编码类型。支持的编码类型包括普通、位混洗、游程、字典和前缀。默认情况下，Kudu 列是未压缩的。Kudu 支持使用 Snappy、zlib 或 LZ4 压缩编解码器进行列压缩。压缩和编码可以显著减少空间开销并提高性能。有关编码和压缩的更多信息，请参考 Kudu 的在线文档。

Note

在 Kudu 的早期版本中，日期和时间被表示为 BIGINT。从 Impala 2.9/CDH 5.12 开始，可以在 Kudu 表中使用时间戳数据类型。然而，有几件事要记住。Kudu 使用 64 位值表示日期和时间列，而 Impala 使用 96 位值表示日期和时间。存储在 Kudu 中时，Impala 生成的纳秒值四舍五入。在读写时间戳列时，Kudu 的 64 位表示和 Impala 的 96 位表示之间存在转换开销。有两种解决方法:使用 Kudu 客户端 API 或 Spark 来插入数据，或者继续使用 BIGINT 来表示日期和时间。 [<sup>ii</sup>](#Sec22)

## 内部和外部 Impala 表

您可以在 Impala 中创建内部和外部表。

### 内部表格

内部表由 Impala 创建和管理。内部表一创建，Impala 就能立即看到。删除和重命名表等管理任务是使用 Impala 执行的。下面是一个如何在 Impala 中创建内部表的例子。

```scala
CREATE TABLE users
(
  id BIGINT,
  name STRING,
  age TINYINT,
  salary FLOAT,
  PRIMARY KEY(id)
)
PARTITION BY HASH PARTITIONS 8
STORED AS KUDU;

```

### 外部表格

通过 Kudu API 和 Spark 创建的 Kudu 表对 Impala 来说并不直接可见。这个表存在于 Kudu 中，但是因为它不是通过 Impala 创建的，所以它不知道这个表的任何信息。必须在 Impala 中创建一个引用 Kudu 表的外部表。删除外部表只会删除 Impala 和 Kudu 表之间的映射，而不会删除 Kudu 中的物理表。下面是一个关于如何在 Impala 中创建一个外部表到一个现有的 Kudu 表的例子。

```scala
CREATE EXTERNAL TABLE users
STORED AS KUDU
TBLPROPERTIES (
  'kudu.table_name' = 'kudu_users'
);

```

## 更改数据

您可以通过 Impala 使用 SQL 语句更改存储在 Kudu 表中的数据，就像传统的关系数据库一样。这就是为什么你会使用 Kudu 而不是不可变的存储格式，比如 ORC 或 Parquet 的主要原因之一。

### 插入行

您可以使用标准的 SQL insert 语句。

```scala
INSERT INTO users VALUES (100, "John Smith", 25, 50000);

```

插入具有多个值的行子子句。

```scala
INSERT INTO users VALUES (100, "John Smith", 25, 50000), (200, "Cindy Nguyen", 38, 120000), (300, "Steve Mankiw", 60, 75000);

```

也支持大容量插入。

```scala
INSERT INTO users SELECT * from users_backup;

```

### 更新行

标准 SQL 更新语句。

```scala
UPDATE users SET age=39 where name = 'Cindy Nguyen';

```

还支持批量更新。

```scala
UPDATE users SET salary=150000 where id > 100;

```

### 打乱行

支持向上插入。如果表中不存在主键，则插入整行。

```scala
UPSERT INTO users VALUES (400, "Mike Jones", 21, 80000);

```

但是，如果主键已经存在，则列将使用新值进行更新。

```scala
UPSERT INTO users VALUES (100, "John Smith", 27, 70000);

```

### 删除行

标准 SQL 删除语句。

```scala
DELETE FROM users WHERE id < 3;

```

还支持更复杂的 Delete 语句。

```scala
DELETE FROM users WHERE id in (SELECT id FROM users WHERE name = 'Steve Mankiw');

```

Note

如第 [2](02.html) 章所述，Kudu 不支持符合 ACID 的事务。如果更新中途失败，将不会回滚。更新后必须执行额外的数据验证，以确保数据完整性。

## 更改模式

Kudu 支持典型的数据库管理任务，比如重命名表、添加和删除范围分区以及删除表。更多信息，请查阅 Kudu 的在线文档。

## 分割

表分区是增强 Kudu 表的性能、可用性和可管理性的常用方法。分区允许将表细分成更小的部分，即片。分区使 Kudu 能够以更精细的粒度访问平板电脑，从而利用分区修剪。所有 Kudu 表都需要进行表分区，表分区对应用程序是完全透明的。Kudu 支持散列、范围、复合散列-范围和散列-散列分区。下面是 Kudu 中分区的几个例子。分区在第 [2](02.html) 章中有更详细的讨论。

### 哈希分区

散列分区使用散列键将行均匀地分布在不同的平板上。

```scala
CREATE TABLE myTable (
 id BIGINT NOT NULL,
 name STRING,
 PRIMARY KEY(id)
)
PARTITION BY HASH PARTITIONS 4
STORED AS KUDU;

```

### 范围划分

范围分区将数据范围分别存储在不同的平板电脑中。

```scala
CREATE TABLE myTable (
  year INT,
  deviceid INT,
  totalamt INT,
  PRIMARY KEY (deviceid, year)
)
PARTITION BY RANGE (year) (
  PARTITION VALUE = 2016,
  PARTITION VALUE = 2017,
  PARTITION VALUE = 2018
)
STORED AS KUDU;

```

### 哈希范围分区

哈希分区将写操作均匀地分布在平板电脑上。范围分区支持分区修剪，并允许添加和删除分区。复合分区结合了两种分区方案的优点，同时限制了它的缺点。对于物联网用例来说，这是一个很好的划分方案。

```scala
CREATE TABLE myTable (
 id BIGINT NOT NULL,
 sensortimestamp BIGINT NOT NULL,
 sensorid INTEGER,
 temperature INTEGER,
 pressure INTEGER,
 PRIMARY KEY(id, sensortimestamp)
)
PARTITION BY HASH (id) PARTITIONS 16,
RANGE (sensortimestamp)
(

PARTITION unix_timestamp('2017-01-01') <= VALUES < unix_timestamp('2018-01-01'),
PARTITION unix_timestamp('2018-01-01') <= VALUES < unix_timestamp('2019-01-01'),
PARTITION unix_timestamp('2019-01-01') <= VALUES < unix_timestamp('2020-01-01')
)
STORED AS KUDU;

```

### 哈希-哈希分区

您的表中可以有多个级别的散列分区。每个分区级别应该使用不同的散列列。

```scala
CREATE TABLE myTable (
  id BIGINT,
  city STRING,
  name STRING
  age TINYINT,
  PRIMARY KEY (id, city)
)
PARTITION BY HASH (id) PARTITIONS 8,
             HASH (city) PARTITIONS 8
STORED AS KUDU;

```

### 列表分区

如果您熟悉 Oracle 等其他关系数据库管理系统，您可能已经使用过列表分区。虽然 Kudu 在技术上没有列表分区，但是您可以使用范围分区来模仿它的行为。

```scala
CREATE TABLE myTable (
  city STRING
  name STRING,
  age TINYINT,
  PRIMARY KEY (city, name)
)
PARTITION BY RANGE (city)
(
  PARTITION VALUE = 'San Francisco',
  PARTITION VALUE = 'Los Angeles',
  PARTITION VALUE = 'San Diego',
  PARTITION VALUE = 'San Jose'
)
STORED AS KUDU;

```

Note

分区不是万能的。它只是优化 Kudu 的众多方法之一。如果使用默认的 Kudu 设置，在将数据摄取到 Kudu 中时，您仍可能会遇到性能问题。确保调整参数 maintenance _ manager _ num _ threads， [<sup>iii</sup>](#Sec22) ，这是维护线程的数量，有助于加速压缩和刷新。您可以监视 bloom_lookups_per_op 指标和内存压力拒绝，以查看压缩和刷新是否会影响性能。您可能需要调整的另一个设置是 memory_limit_hard_bytes，它控制分配给 Kudu 守护进程的内存总量。 [<sup>iv</sup>](#Sec22) 更多详情参考在线 Kudu 文档。

## 使用 JDBC 与阿帕奇黑斑羚和库杜

流行的 BI 和数据可视化工具，如 Power BI、Tableau、Qlik、OBIEE 和 MicroStrategy(仅举几个例子)可以使用 JDBC/ODBC 访问 Apache Impala 和 Kudu。黑斑羚 JDBC 的驱动程序可以从 Cloudera 的网站上下载。Progress DataDirect JDBC 驱动程序是另一种选择。 [<sup>v</sup>](#Sec22) 在某些情况下，来自不同公司的一些 JDBC 驱动程序具有额外的性能特征。你的经历可能会有所不同。图 [4-1](#Fig1) 显示了一个 Zoomdata 仪表板的样本截图，该仪表板通过 Impala JDBC/ODBC 可视化存储在 Kudu 中的数据。

![A456459_1_En_4_Fig1_HTML.jpg](img/A456459_1_En_4_Fig1_HTML.jpg)

图 4-1

Kudu data accessible from ZoomData in real time

## 与 SQL Server 链接服务器和 Oracle 网关的联盟

您可以创建从 SQL Server 和 Oracle 到 Impala 的数据库链接。如果来回复制数据太麻烦并且数据相对较小，这有时会很有用。此外，如果您需要从 SQL Server 或 Oracle 接近实时地访问存储在 Kudu 中的最新数据，而 ETL 太慢，那么通过数据库链接访问数据是一种选择。下面是一个如何在 SQL Server 中创建数据库链接的示例。然后，用户可以访问存储在远程 Impala 环境中的数据(如清单 [4-1](#Par49) 所示)。注意，通常建议在执行查询时使用 OpenQuery，以确保查询在远程服务器上执行。

```scala
EXEC master.dbo.sp_addlinkedserver
 @server = 'ClouderaImpala', @srvproduct='ClouderaImpala',
 @provider='MSDASQL', @datasrc='ClouderaImpala',
 @provstr='Provider=MSDASQL.1;Persist Security Info=True;User ID=;Password=';

SELECT * FROM OpenQuery(ClouderaImpala, 'SELECT * FROM order_items');

SELECT * FROM OpenQuery(ClouderaImpala, 'SELECT * FROM orders');

SELECT count(*)
FROM [ClouderaImpala].[IMPALA].[default].order_items

SELECT count(*)
FROM [ClouderaImpala].[IMPALA].[default].orders

create view OrderItems_v as
SELECT * FROM OpenQuery(ClouderaImpala, 'SELECT * from order_items');

create view Orders_v as
SELECT * FROM OpenQuery(ClouderaImpala, 'SELECT * from orders');

create view OrderDetail_v as
SELECT * FROM OpenQuery(ClouderaImpala, 'SELECT o.order_id,oi.order_item_id, o.order_date,o.order_status
FROM [IMPALA].[default].orders o, [IMPALA].[default].order_items oi
where o.order_id=oi.order_item_order_id')

Listing 4-1Creating and using linked server from SQL Server to Impala

```

您可以使用 Oracle 的 ODBC 异构网关创建从 Oracle 到 Impala 的数据库链接。有关更多详细信息，请参考 Oracle 文档。

如果访问中小型数据集，数据库链接是合适的。如果您需要一个成熟的数据虚拟化工具，您可能会考虑使用 Polybase、Denodo 或 TIBCO 数据虚拟化(以前由 Cisco 拥有)。

## 摘要

Impala 为 Kudu 提供了强大的 MPP SQL 引擎。总之，它们在性能和可伸缩性方面可以与传统的数据仓库平台相媲美。Kudu 提交者和贡献者正在努力增加更多的特性和功能。第 2 章提供了对 Kudu 的深入讨论，包括它的局限性。想了解更多关于黑斑羚的信息，我建议你参考第三章[。第 8 章](03.html)[讲述了使用 Impala 和 Kudu 进行大数据仓储。第](08.html) [9 章](09.html)向用户展示如何使用 Impala 和 Kudu 进行实时数据可视化。

## 参考

1.  微软；《理解 IEEE 浮点错误完整教程》，微软，2018， [`https://support.microsoft.com/en-us/help/42980/-complete-tutorial-to-understand-ieee-floating-point-errors`](https://support.microsoft.com/en-us/help/42980/-complete-tutorial-to-understand-ieee-floating-point-errors)
2.  阿帕奇黑斑羚；“时间戳数据类型”，Apache Impala，2018， [`https://impala.apache.org/docs/build/html/topics/impala_timestamp.html`](https://impala.apache.org/docs/build/html/topics/impala_timestamp.html)
3.  Cloudera《阿帕奇库度后台维护任务》，Cloudera，2018， [`https://www.cloudera.com/documentation/kudu/latest/topics/kudu_background_tasks.html`](https://www.cloudera.com/documentation/kudu/latest/topics/kudu_background_tasks.html)
4.  托德·利普孔；“Re:如何计算`维护 _ 管理器 _ 线程数'的最优值”，Todd Lipcon，2017，`https://www.mail-archive.com/user@kudu.apache.org/msg00358.html`
5.  Saikrishna Teja Bobba《教程:用 Apache Kudu 使用 Impala JDBC 和 SQL》，《进度》2017， [`https://www.progress.com/blogs/tutorial-using-impala-jdbc-and-sql-with-apache-kudu`](https://www.progress.com/blogs/tutorial-using-impala-jdbc-and-sql-with-apache-kudu)